import os
import re
from typing import List, Dict, Any, Tuple
from pathlib import Path
from docx import Document
import json

class ContractTextSplitter:
    """åˆåŒæ–‡æ¡£ä¸“ç”¨æ–‡æœ¬åˆ†å‰²å™¨ï¼Œé’ˆå¯¹åˆåŒç‰¹ç‚¹ä¼˜åŒ–"""
    
    def __init__(self, chunk_size=1000, chunk_overlap=150, min_chunk_length=30):
        """
        åˆå§‹åŒ–åˆåŒåˆ†å‰²å™¨
        
        Args:
            chunk_size: å—å¤§å°ï¼ˆåˆåŒé€šå¸¸æ¡æ¬¾è¾ƒé•¿ï¼‰
            chunk_overlap: å—é‡å å¤§å°
            min_chunk_length: æœ€å°å—é•¿åº¦
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.min_chunk_length = min_chunk_length
        
        # åˆåŒä¸“ç”¨æ¡æ¬¾è¯†åˆ«æ¨¡å¼ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰
        self.contract_clause_patterns = [
            # 1. åˆåŒä¸“ç”¨æ¡æ¬¾ï¼šç¬¬ä¸€æ¡ã€ç¬¬1æ¡
            (r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡é›¶]+æ¡[^\n]*', 'ä¸­æ–‡æ¡æ¬¾', 1),
            (r'ç¬¬\d+æ¡[^\n]*', 'æ•°å­—æ¡æ¬¾', 2),
            
            # 2. åˆåŒç« èŠ‚ï¼šç¬¬ä¸€ç« ã€ç¬¬ä¸€èŠ‚
            (r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ç« [^\n]*', 'ç« èŠ‚æ ‡é¢˜', 3),
            (r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+èŠ‚[^\n]*', 'å°èŠ‚æ ‡é¢˜', 4),
            
            # 3. åˆåŒå½“äº‹äººä¿¡æ¯ï¼ˆé‡è¦éƒ¨åˆ†ï¼‰
            (r'^ç”²æ–¹[ï¼š:][^\n]*', 'ç”²æ–¹ä¿¡æ¯', 5),
            (r'^ä¹™æ–¹[ï¼š:][^\n]*', 'ä¹™æ–¹ä¿¡æ¯', 6),
            (r'^å€Ÿæ¬¾äºº[ï¼š:][^\n]*', 'å€Ÿæ¬¾äººä¿¡æ¯', 7),
            (r'^è´·æ¬¾äºº[ï¼š:][^\n]*', 'è´·æ¬¾äººä¿¡æ¯', 8),
            (r'^å‡ºå€Ÿäºº[ï¼š:][^\n]*', 'å‡ºå€Ÿäººä¿¡æ¯', 9),
            (r'^ä¿è¯äºº[ï¼š:][^\n]*', 'ä¿è¯äººä¿¡æ¯', 10),
            
            # 4. åˆåŒæ ¸å¿ƒæ¡æ¬¾æ ‡é¢˜
            (r'^è´·æ¬¾é‡‘é¢[ï¼š:][^\n]*', 'é‡‘é¢æ¡æ¬¾', 11),
            (r'^è´·æ¬¾åˆ©ç‡[ï¼š:][^\n]*', 'åˆ©ç‡æ¡æ¬¾', 12),
            (r'^è¿˜æ¬¾æ–¹å¼[ï¼š:][^\n]*', 'è¿˜æ¬¾æ¡æ¬¾', 13),
            (r'^è¿çº¦è´£ä»»[ï¼š:][^\n]*', 'è¿çº¦æ¡æ¬¾', 14),
            (r'^äº‰è®®è§£å†³[ï¼š:][^\n]*', 'äº‰è®®æ¡æ¬¾', 15),
            (r'^æ‹…ä¿æ¡æ¬¾[ï¼š:][^\n]*', 'æ‹…ä¿æ¡æ¬¾', 16),
            (r'^ä¿å¯†æ¡æ¬¾[ï¼š:][^\n]*', 'ä¿å¯†æ¡æ¬¾', 17),
            
            # 5. ç¼–å·æ¡æ¬¾ï¼š1.ã€1.1ã€(1)ã€â‘ 
            (r'^\d+[\.ã€][^\n]*', 'æ•°å­—ç¼–å·', 18),
            (r'^\d+\.\d+[^\n]*', 'å°æ•°ç¼–å·', 19),
            (r'^[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+[ï¼‰)][^\n]*', 'æ‹¬å·ç¼–å·', 20),
            (r'^[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©][^\n]*', 'å¸¦åœˆç¼–å·', 21),
            
            # 6. ä¸­æ–‡åºå·ï¼šä¸€ã€äºŒã€
            (r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.][^\n]*', 'ä¸­æ–‡åºå·', 22),
            
            # 7. å¤§å†™é‡‘é¢å’Œæ•°å­—ï¼ˆåˆåŒç‰¹æœ‰ï¼‰
            (r'äººæ°‘å¸[é›¶å£¹è´°åè‚†ä¼é™†æŸ’æŒç–æ‹¾ä½°ä»Ÿä¸‡äº¿å…ƒæ•´]+[^\n]*', 'å¤§å†™é‡‘é¢', 23),
            (r'Â¥\s*\d+[,\d]*\.?\d*[^\n]*', 'è´§å¸é‡‘é¢', 24),
            
            # 8. æ—¥æœŸæ¡æ¬¾ï¼ˆåˆåŒé‡è¦ä¿¡æ¯ï¼‰
            (r'^\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥[^\n]*', 'æ—¥æœŸæ¡æ¬¾', 25),
            (r'^[åˆåŒåè®®]æœŸ[é™é—´][ï¼š:][^\n]*', 'æœŸé™æ¡æ¬¾', 26),
        ]
        
        # åˆåŒå…³é”®è¯ï¼Œç”¨äºè¯†åˆ«æ¡æ¬¾ç±»å‹
        self.contract_keywords = {
            'å½“äº‹äºº': 'å½“äº‹äººä¿¡æ¯',
            'è´·æ¬¾': 'è´·æ¬¾æ¡æ¬¾',
            'å€Ÿæ¬¾': 'å€Ÿæ¬¾æ¡æ¬¾',
            'è¿˜æ¬¾': 'è¿˜æ¬¾æ¡æ¬¾',
            'åˆ©æ¯': 'åˆ©æ¯æ¡æ¬¾',
            'åˆ©ç‡': 'åˆ©ç‡æ¡æ¬¾',
            'æ‹…ä¿': 'æ‹…ä¿æ¡æ¬¾',
            'æŠµæŠ¼': 'æŠµæŠ¼æ¡æ¬¾',
            'è´¨æŠ¼': 'è´¨æŠ¼æ¡æ¬¾',
            'ä¿è¯': 'ä¿è¯æ¡æ¬¾',
            'è¿çº¦': 'è¿çº¦æ¡æ¬¾',
            'èµ”å¿': 'èµ”å¿æ¡æ¬¾',
            'äº‰è®®': 'äº‰è®®æ¡æ¬¾',
            'ä»²è£': 'ä»²è£æ¡æ¬¾',
            'è¯‰è®¼': 'è¯‰è®¼æ¡æ¬¾',
            'ä¿å¯†': 'ä¿å¯†æ¡æ¬¾',
            'ç”Ÿæ•ˆ': 'ç”Ÿæ•ˆæ¡æ¬¾',
            'ç»ˆæ­¢': 'ç»ˆæ­¢æ¡æ¬¾',
            'è§£é™¤': 'è§£é™¤æ¡æ¬¾',
            'é€šçŸ¥': 'é€šçŸ¥æ¡æ¬¾',
            'é€è¾¾': 'é€è¾¾æ¡æ¬¾',
            'é™„ä»¶': 'é™„ä»¶æ¡æ¬¾',
            'ç­¾å­—': 'ç­¾å­—æ¡æ¬¾',
            'ç›–ç« ': 'ç›–ç« æ¡æ¬¾',
        }
    
    def split_by_contract_clauses(self, text: str) -> List[Dict[str, Any]]:
        """
        æŒ‰åˆåŒæ¡æ¬¾åˆ†å‰²æ–‡æœ¬ï¼Œè¿”å›å¸¦å…ƒæ•°æ®çš„å—åˆ—è¡¨
        
        Args:
            text: è¦åˆ†å‰²çš„æ–‡æœ¬
            
        Returns:
            åˆ†å‰²åçš„æ¡æ¬¾åˆ—è¡¨ï¼Œæ¯ä¸ªæ¡æ¬¾åŒ…å«æ–‡æœ¬å’Œå…ƒæ•°æ®
        """
        if not text or not text.strip():
            return []
        
        # æŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„æ¡æ¬¾å¼€å§‹ä½ç½®
        clause_positions = self._find_all_clause_positions(text)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ¡æ¬¾ï¼Œå°è¯•æŒ‰æ®µè½åˆ†å‰²
        if not clause_positions:
            return self._split_by_paragraphs(text)
        
        # æŒ‰æ¡æ¬¾ä½ç½®åˆ†å‰²
        clauses = []
        
        # å¤„ç†ç¬¬ä¸€ä¸ªæ¡æ¬¾ä¹‹å‰çš„å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if clause_positions[0][0] > 0:
            pre_text = text[:clause_positions[0][0]].strip()
            if pre_text and len(pre_text) >= self.min_chunk_length:
                clause_type = self._detect_clause_type(pre_text)
                clauses.append({
                    'text': pre_text,
                    'type': clause_type,
                    'header': 'åˆåŒå‰è¨€',
                    'priority': 0
                })
        
        # æŒ‰æ¡æ¬¾ä½ç½®åˆ†å‰²
        for i in range(len(clause_positions)):
            start_pos, header, clause_type, priority = clause_positions[i]
            
            # ç¡®å®šç»“æŸä½ç½®
            if i + 1 < len(clause_positions):
                end_pos = clause_positions[i+1][0]
            else:
                end_pos = len(text)
            
            # æå–æ¡æ¬¾æ–‡æœ¬
            clause_text = text[start_pos:end_pos].strip()
            
            if clause_text and len(clause_text) >= self.min_chunk_length:
                clauses.append({
                    'text': clause_text,
                    'type': clause_type,
                    'header': header.strip(),
                    'priority': priority
                })
        
        return clauses
    
    def _find_all_clause_positions(self, text: str) -> List[Tuple[int, str, str, int]]:
        """æŸ¥æ‰¾æ‰€æœ‰åˆåŒæ¡æ¬¾çš„ä½ç½®"""
        clause_positions = []
        
        # ä½¿ç”¨æ‰€æœ‰æ¨¡å¼æŸ¥æ‰¾
        for pattern, clause_type, priority in self.contract_clause_patterns:
            try:
                for match in re.finditer(pattern, text, re.MULTILINE):
                    start_pos = match.start()
                    header = match.group().strip()
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»è®°å½•è¿‡ç›¸ä¼¼ä½ç½®ï¼ˆé¿å…é‡å¤ï¼‰
                    if not self._is_position_already_recorded(start_pos, clause_positions):
                        clause_positions.append((start_pos, header, clause_type, priority))
            except re.error:
                continue
        
        # æŒ‰ä½ç½®æ’åº
        clause_positions.sort(key=lambda x: x[0])
        
        return clause_positions
    
    def _is_position_already_recorded(self, position: int, positions: List[Tuple]) -> bool:
        """æ£€æŸ¥ä½ç½®æ˜¯å¦å·²ç»è¢«è®°å½•è¿‡"""
        for pos, _, _, _ in positions:
            if abs(position - pos) < 5:  # å…è®¸5ä¸ªå­—ç¬¦çš„è¯¯å·®
                return True
        return False
    
    def _detect_clause_type(self, text: str) -> str:
        """æ ¹æ®å†…å®¹æ£€æµ‹æ¡æ¬¾ç±»å‹"""
        first_line = text.split('\n')[0] if '\n' in text else text
        first_line = first_line.strip()
        
        # æ£€æŸ¥æ˜¯å¦åŒ¹é…å·²çŸ¥æ¨¡å¼
        for pattern, clause_type, _ in self.contract_clause_patterns:
            if re.match(pattern, first_line):
                return clause_type
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆåŒå…³é”®è¯
        for keyword, clause_type in self.contract_keywords.items():
            if keyword in first_line[:50]:  # åªæ£€æŸ¥å‰50ä¸ªå­—ç¬¦
                return clause_type
        
        # æ ¹æ®å†…å®¹é•¿åº¦åˆ¤æ–­
        if len(text) < 100:
            return 'çŸ­æ¡æ¬¾'
        elif len(text) < 300:
            return 'ä¸­ç­‰æ¡æ¬¾'
        else:
            return 'é•¿æ¡æ¬¾'
    
    def _split_by_paragraphs(self, text: str) -> List[Dict[str, Any]]:
        """æŒ‰æ®µè½åˆ†å‰²æ–‡æœ¬ï¼ˆå½“æ‰¾ä¸åˆ°æ˜æ˜¾æ¡æ¬¾æ—¶ä½¿ç”¨ï¼‰"""
        if not text:
            return []
        
        # åˆ†å‰²æ®µè½ï¼ˆä¸¤ä¸ªä»¥ä¸Šæ¢è¡Œï¼‰
        paragraphs = re.split(r'\n\s*\n+', text)
        clauses = []
        
        for para in paragraphs:
            para = para.strip()
            if para and len(para) >= self.min_chunk_length:
                clause_type = self._detect_clause_type(para)
                
                # æå–æ®µè½ç¬¬ä¸€è¡Œä½œä¸ºæ ‡é¢˜
                header = para.split('\n')[0].strip()
                if len(header) > 50:
                    header = header[:50] + "..."
                
                clauses.append({
                    'text': para,
                    'type': clause_type,
                    'header': header,
                    'priority': 999  # ä½ä¼˜å…ˆçº§
                })
        
        return clauses
    
    def identify_contract_party(self, text: str) -> str:
        """è¯†åˆ«åˆåŒå½“äº‹äººç±»å‹"""
        if re.search(r'ç”²æ–¹[ï¼š:]', text[:200]):
            return 'ç”²æ–¹'
        elif re.search(r'ä¹™æ–¹[ï¼š:]', text[:200]):
            return 'ä¹™æ–¹'
        elif re.search(r'å€Ÿæ¬¾äºº[ï¼š:]', text[:200]):
            return 'å€Ÿæ¬¾äºº'
        elif re.search(r'è´·æ¬¾äºº[ï¼š:]', text[:200]):
            return 'è´·æ¬¾äºº'
        elif re.search(r'å‡ºå€Ÿäºº[ï¼š:]', text[:200]):
            return 'å‡ºå€Ÿäºº'
        elif re.search(r'ä¿è¯äºº[ï¼š:]', text[:200]):
            return 'ä¿è¯äºº'
        elif re.search(r'æŠµæŠ¼äºº[ï¼š:]', text[:200]):
            return 'æŠµæŠ¼äºº'
        else:
            return 'å…¶ä»–'

class ContractDocumentProcessor:
    """åˆåŒæ–‡æ¡£å¤„ç†å™¨ï¼Œä¸“é—¨å¤„ç†åˆåŒæ–‡æ¡£"""
    
    def __init__(self, contracts_dir: str = "../docs/contracts", chunk_size=1000, min_chunk_length=30):
        """
        åˆå§‹åŒ–åˆåŒå¤„ç†å™¨
        
        Args:
            contracts_dir: åˆåŒæ–‡æ¡£ç›®å½•è·¯å¾„
            chunk_size: å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            min_chunk_length: æœ€å°å—é•¿åº¦
        """
        self.contracts_dir = Path(contracts_dir)
        self.docs = []
        self.splitter = ContractTextSplitter(
            chunk_size=chunk_size, 
            min_chunk_length=min_chunk_length
        )
    
    def extract_docx_text(self, file_path: Path) -> Dict[str, Any]:
        """ä»docxæ–‡ä»¶ä¸­æå–åˆåŒæ–‡æœ¬"""
        try:
            doc = Document(file_path)
            
            # æå–æ‰€æœ‰æ®µè½
            paragraphs = []
            for para in doc.paragraphs:
                text = para.text.strip()
                if text:
                    paragraphs.append(text)
            
            full_text = '\n\n'.join(paragraphs)
            
            # å°è¯•æå–åˆåŒæ ‡é¢˜ï¼ˆç”¨äºæ˜¾ç¤ºï¼Œä¸ä½œä¸ºæ–‡ä»¶å¤¹åï¼‰
            contract_title = "æœªå‘½ååˆåŒ"
            if paragraphs:
                # æ£€æŸ¥å‰å‡ è¡Œæ˜¯å¦æœ‰"åˆåŒ"ã€"åè®®"ç­‰å…³é”®è¯
                for i in range(min(5, len(paragraphs))):
                    line = paragraphs[i]
                    if any(keyword in line for keyword in ['åˆåŒ', 'åè®®', 'åè®®ä¹¦', 'å¥‘çº¦', 'åˆçº¦', 'çº¦å®šä¹¦']):
                        contract_title = line.strip()
                        if len(contract_title) > 100:
                            contract_title = contract_title[:100] + "..."
                        break
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
                    contract_title = Path(file_path).stem
            
            return {
                'file_name': file_path.name,  # å¸¦æ‰©å±•åçš„æ–‡ä»¶å
                'file_stem': Path(file_path).stem,  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
                'contract_title': contract_title,
                'file_path': str(file_path),
                'full_text': full_text,
                'total_paragraphs': len(paragraphs),
                'extraction_success': True
            }
        except Exception as e:
            print(f"æå–åˆåŒæ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return {
                'file_name': file_path.name,
                'file_stem': Path(file_path).stem,
                'contract_title': "æå–å¤±è´¥",
                'file_path': str(file_path),
                'full_text': '',
                'error': str(e),
                'extraction_success': False
            }
    
    def load_all_documents(self) -> List[Dict[str, Any]]:
        """åŠ è½½ç›®å½•ä¸­çš„æ‰€æœ‰åˆåŒæ–‡æ¡£"""
        if not self.contracts_dir.exists():
            print(f"åˆåŒç›®å½•ä¸å­˜åœ¨: {self.contracts_dir}")
            return []
        
        # æ”¯æŒå¤šç§æ–‡æ¡£æ‰©å±•å
        extensions = ["*.docx", "*.doc"]
        contract_files = []
        for ext in extensions:
            contract_files.extend(list(self.contracts_dir.glob(ext)))
        
        print(f"æ‰¾åˆ° {len(contract_files)} ä¸ªåˆåŒæ–‡ä»¶")
        
        all_docs = []
        for file_path in contract_files:
            print(f"æ­£åœ¨å¤„ç†: {file_path.name}")
            doc_data = self.extract_docx_text(file_path)
            
            if doc_data['extraction_success']:
                all_docs.append(doc_data)
                print(f"  âœ“ æˆåŠŸæå–ï¼Œ{len(doc_data['full_text'])} å­—ç¬¦")
            else:
                print(f"  âœ— æå–å¤±è´¥: {doc_data.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        self.docs = all_docs
        return all_docs
    
    def process_documents(self) -> List[Dict[str, Any]]:
        """å¤„ç†å¹¶åˆ†å‰²æ‰€æœ‰åˆåŒæ–‡æ¡£"""
        if not self.docs:
            self.load_all_documents()
        
        all_chunks = []
        
        for doc in self.docs:
            if not doc['extraction_success']:
                continue
            
            print(f"åˆ†å‰²åˆåŒ: {doc['file_stem']} ({doc['file_name']})")
            
            # ä½¿ç”¨åˆåŒä¸“ç”¨åˆ†å‰²å™¨
            clauses = self.splitter.split_by_contract_clauses(doc['full_text'])
            
            print(f"  åˆ†å‰²ä¸º {len(clauses)} ä¸ªæ¡æ¬¾")
            
            # ç»Ÿè®¡æ¡æ¬¾ç±»å‹
            clause_types = {}
            for clause in clauses:
                clause_type = clause['type']
                clause_types[clause_type] = clause_types.get(clause_type, 0) + 1
            
            # æ˜¾ç¤ºä¸»è¦æ¡æ¬¾ç±»å‹
            if clause_types:
                main_types = sorted(clause_types.items(), key=lambda x: x[1], reverse=True)[:3]
                print(f"  ä¸»è¦æ¡æ¬¾ç±»å‹: {', '.join([f'{t[0]}({t[1]})' for t in main_types])}")
            
            # æ·»åŠ å…ƒæ•°æ®
            for i, clause in enumerate(clauses):
                # è¯†åˆ«å½“äº‹äºº
                party = self.splitter.identify_contract_party(clause['text'])
                
                all_chunks.append({
                    'text': clause['text'],
                    'metadata': {
                        'source': doc['file_name'],
                        'source_stem': doc['file_stem'],  # æ·»åŠ ä¸å«æ‰©å±•åçš„æ–‡ä»¶å
                        'contract_title': doc['contract_title'],
                        'file_path': doc['file_path'],
                        'chunk_index': i,
                        'total_chunks_in_doc': len(clauses),
                        'chunk_size': len(clause['text']),
                        'clause_type': clause['type'],
                        'clause_header': clause['header'],
                        'contract_party': party,
                        'clause_priority': clause['priority'],
                        'chunk_preview': clause['text'][:120].replace('\n', ' ') + ("..." if len(clause['text']) > 120 else "")
                    }
                })
        
        return all_chunks
    
    def save_results(self, chunks: List[Dict[str, Any]], output_dir: str = "./contract_chunks"):
        """ä¿å­˜åˆåŒåˆ†å‰²ç»“æœ - æŒ‰åˆåŒæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰åˆ›å»ºæ–‡ä»¶å¤¹"""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # æŒ‰åˆåŒåˆ†ç»„
        contracts_groups = {}
        for chunk in chunks:
            source = chunk['metadata']['source']
            if source not in contracts_groups:
                contracts_groups[source] = []
            contracts_groups[source].append(chunk)
        
        # ä¸ºæ¯ä¸ªåˆåŒåˆ›å»ºæ–‡ä»¶å¤¹å¹¶ä¿å­˜
        contract_folders = {}
        folder_names_used = {}  # ç”¨äºè®°å½•å·²ä½¿ç”¨çš„æ–‡ä»¶å¤¹åï¼Œé¿å…é‡å¤
        
        for source, contract_chunks in contracts_groups.items():
            # ä½¿ç”¨æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºæ–‡ä»¶å¤¹å
            file_stem = contract_chunks[0]['metadata']['source_stem'] if contract_chunks else Path(source).stem
            
            # æ¸…ç†æ–‡ä»¶å¤¹åä¸­çš„éæ³•å­—ç¬¦
            safe_folder_name = self._make_valid_folder_name(file_stem)
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰åŒåæ–‡ä»¶å¤¹ï¼Œå¦‚æœæœ‰åˆ™æ·»åŠ åºå·
            original_name = safe_folder_name
            counter = 1
            while safe_folder_name in folder_names_used:
                safe_folder_name = f"{original_name}_{counter}"
                counter += 1
            
            folder_names_used[safe_folder_name] = True
            
            contract_folder = output_path / safe_folder_name
            contract_folder.mkdir(exist_ok=True)
            
            contract_folders[source] = {
                'folder_path': str(contract_folder),
                'folder_name': safe_folder_name,
                'file_stem': file_stem,
                'contract_title': contract_chunks[0]['metadata']['contract_title'] if contract_chunks else "æœªå‘½ååˆåŒ"
            }
            
            # æŒ‰å—ç´¢å¼•æ’åº
            contract_chunks.sort(key=lambda x: x['metadata']['chunk_index'])
            
            # ä¿å­˜è¯¥åˆåŒçš„å—åˆ°è‡ªå·±çš„æ–‡ä»¶å¤¹
            contract_json_path = contract_folder / "chunks.json"
            with open(contract_json_path, 'w', encoding='utf-8') as f:
                json.dump(contract_chunks, f, ensure_ascii=False, indent=2)
            
            # ä¿å­˜è¯¥åˆåŒçš„ç»Ÿè®¡ä¿¡æ¯
            contract_stats_path = contract_folder / "statistics.txt"
            with open(contract_stats_path, 'w', encoding='utf-8') as f:
                self._write_contract_statistics(f, source, contract_chunks)
            
            # æ˜¾ç¤ºä¿å­˜ä¿¡æ¯
            contract_title = contract_chunks[0]['metadata']['contract_title'] if contract_chunks else "æœªå‘½ååˆåŒ"
            print(f"  âœ“ åˆåŒ '{contract_title}' çš„åˆ†å‰²ç»“æœå·²ä¿å­˜åˆ°: {contract_folder}/")
        
        # ä¿å­˜æ€»çš„ç»Ÿè®¡ä¿¡æ¯
        stats_path = output_path / "contracts_split_statistics.txt"
        with open(stats_path, 'w', encoding='utf-8') as f:
            self._write_overall_statistics(f, chunks, contracts_groups, contract_folders)
        
        print(f"âœ“ æ€»ä½“ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_path}")
        
        return str(output_path)
    
    def _make_valid_folder_name(self, name: str) -> str:
        """å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºæœ‰æ•ˆçš„æ–‡ä»¶å¤¹å"""
        if not name:
            return "æœªå‘½ååˆåŒ"
        
        # ç§»é™¤éæ³•æ–‡ä»¶åå­—ç¬¦
        invalid_chars = r'[<>:"/\\|?*\n\r\t]'
        valid_name = re.sub(invalid_chars, '_', name)
        
        # ç§»é™¤é¦–å°¾ç©ºæ ¼å’Œç‚¹
        valid_name = valid_name.strip('. ')
        
        # ç§»é™¤è¿ç»­çš„ä¸‹åˆ’çº¿
        valid_name = re.sub(r'_+', '_', valid_name)
        
        # é™åˆ¶é•¿åº¦
        if len(valid_name) > 80:
            valid_name = valid_name[:80]
        
        # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
        if not valid_name or valid_name.isspace():
            valid_name = "æœªå‘½ååˆåŒ"
        
        return valid_name
    
    def _write_contract_statistics(self, f, source: str, contract_chunks: List[Dict[str, Any]]):
        """å†™å…¥å•ä¸ªåˆåŒçš„ç»Ÿè®¡ä¿¡æ¯"""
        file_stem = contract_chunks[0]['metadata']['source_stem'] if contract_chunks else Path(source).stem
        contract_title = contract_chunks[0]['metadata']['contract_title'] if contract_chunks else "æœªå‘½ååˆåŒ"
        
        f.write("=" * 80 + "\n")
        f.write(f"åˆåŒåˆ†å‰²ç»Ÿè®¡\n")
        f.write(f"åˆåŒæ–‡ä»¶: {source}\n")
        f.write(f"æ–‡ä»¶å(ä¸å«æ‰©å±•å): {file_stem}\n")
        f.write(f"åˆåŒæ ‡é¢˜: {contract_title}\n")
        f.write("=" * 80 + "\n\n")
        
        f.write(f"ğŸ“Š åˆåŒç»Ÿè®¡\n")
        f.write(f"  åˆåŒæ–‡ä»¶: {source}\n")
        f.write(f"  æ–‡ä»¶å: {file_stem}\n")
        f.write(f"  åˆåŒæ ‡é¢˜: {contract_title}\n")
        f.write(f"  æ¡æ¬¾æ€»æ•°: {len(contract_chunks)}\n")
        
        if contract_chunks:
            avg_chunk_size = sum(len(c['text']) for c in contract_chunks) / len(contract_chunks)
            max_chunk_size = max(len(c['text']) for c in contract_chunks)
            min_chunk_size = min(len(c['text']) for c in contract_chunks)
            
            f.write(f"  å¹³å‡æ¡æ¬¾å¤§å°: {avg_chunk_size:.0f} å­—ç¬¦\n")
            f.write(f"  æœ€å¤§æ¡æ¬¾å¤§å°: {max_chunk_size} å­—ç¬¦\n")
            f.write(f"  æœ€å°æ¡æ¬¾å¤§å°: {min_chunk_size} å­—ç¬¦\n")
            
            # æŒ‰æ¡æ¬¾ç±»å‹ç»Ÿè®¡
            clause_types = {}
            party_stats = {}
            for chunk in contract_chunks:
                clause_type = chunk['metadata']['clause_type']
                clause_types[clause_type] = clause_types.get(clause_type, 0) + 1
                
                party = chunk['metadata']['contract_party']
                party_stats[party] = party_stats.get(party, 0) + 1
            
            f.write(f"\nğŸ“‹ æ¡æ¬¾ç±»å‹ç»Ÿè®¡\n")
            for clause_type, count in sorted(clause_types.items(), key=lambda x: x[1], reverse=True):
                percentage = count / len(contract_chunks) * 100
                f.write(f"  {clause_type}: {count} æ¡ ({percentage:.1f}%)\n")
            
            f.write(f"\nğŸ‘¥ å½“äº‹äººåˆ†å¸ƒ\n")
            for party, count in sorted(party_stats.items(), key=lambda x: x[1], reverse=True):
                percentage = count / len(contract_chunks) * 100
                f.write(f"  {party}: {count} æ¡ ({percentage:.1f}%)\n")
            
            # æ£€æŸ¥è¿ç»­æ€§
            indices = [c['metadata']['chunk_index'] for c in contract_chunks]
            if indices:
                min_idx = min(indices)
                max_idx = max(indices)
                
                # æ‰¾å‡ºç¼ºå¤±çš„ç´¢å¼•
                all_indices = set(range(min_idx, max_idx + 1))
                present_indices = set(indices)
                missing_indices = sorted(all_indices - present_indices)
                
                if missing_indices:
                    f.write(f"\nâš  è¿ç»­æ€§æ£€æŸ¥\n")
                    f.write(f"  ç¼ºå¤±æ¡æ¬¾ç´¢å¼•: {missing_indices}\n")
                    f.write(f"  ç¼ºå¤±æ¡æ¬¾æ•°é‡: {len(missing_indices)}\n")
            
            # åˆ—å‡ºé‡è¦æ¡æ¬¾ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
            f.write(f"\nğŸ” é‡è¦æ¡æ¬¾åˆ—è¡¨\n")
            important_clauses = [c for c in contract_chunks if c['metadata']['clause_priority'] <= 15]
            
            if important_clauses:
                f.write(f"  å…±æ‰¾åˆ° {len(important_clauses)} ä¸ªé‡è¦æ¡æ¬¾:\n")
                for chunk in important_clauses[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ª
                    idx = chunk['metadata']['chunk_index']
                    clause_type = chunk['metadata']['clause_type']
                    header = chunk['metadata']['clause_header']
                    size = chunk['metadata']['chunk_size']
                    
                    f.write(f"  æ¡æ¬¾ {idx:3d}: [{clause_type}] {header[:40]} ({size:4d}å­—ç¬¦)\n")
            else:
                f.write(f"  æœªè¯†åˆ«åˆ°é‡è¦æ¡æ¬¾\n")
            
            # åˆ—å‡ºæ‰€æœ‰æ¡æ¬¾
            f.write(f"\n{'â”€' * 60}\n")
            f.write(f"å®Œæ•´æ¡æ¬¾åˆ—è¡¨ (å…±{len(contract_chunks)}ä¸ªæ¡æ¬¾):\n")
            f.write(f"{'â”€' * 60}\n")
            
            for chunk in contract_chunks:
                idx = chunk['metadata']['chunk_index']
                clause_type = chunk['metadata']['clause_type']
                header = chunk['metadata']['clause_header']
                party = chunk['metadata']['contract_party']
                size = chunk['metadata']['chunk_size']
                
                # æå–é¢„è§ˆæ–‡æœ¬
                preview = chunk['text'][:80].replace('\n', ' ')
                if len(chunk['text']) > 80:
                    preview += "..."
                
                f.write(f"æ¡æ¬¾ {idx:3d}: [{party}][{clause_type}] {header} ({size:4d}å­—ç¬¦)\n")
                if chunk['metadata']['clause_priority'] <= 10:
                    f.write(f"      é¢„è§ˆ: {preview}\n")
    
    def _write_overall_statistics(self, f, chunks: List[Dict[str, Any]], 
                                 contracts_groups: Dict[str, List], contract_folders: Dict[str, dict]):
        """å†™å…¥æ€»ä½“ç»Ÿè®¡ä¿¡æ¯"""
        f.write("=" * 80 + "\n")
        f.write("åˆåŒæ–‡æ¡£åˆ†å‰²æ€»ä½“ç»Ÿè®¡æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        
        # æ€»ä½“ç»Ÿè®¡
        f.write(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡\n")
        f.write(f"  åˆåŒæ€»æ•°: {len(contracts_groups)}\n")
        f.write(f"  æ¡æ¬¾æ€»æ•°: {len(chunks)}\n")
        
        if chunks:
            avg_chunk_size = sum(len(c['text']) for c in chunks) / len(chunks)
            f.write(f"  å¹³å‡æ¡æ¬¾å¤§å°: {avg_chunk_size:.0f} å­—ç¬¦\n")
        
        # å„åˆåŒç»Ÿè®¡æ‘˜è¦
        f.write(f"\nğŸ“ å„åˆåŒç»Ÿè®¡æ‘˜è¦\n")
        for source, contract_chunks in contracts_groups.items():
            contract_info = contract_folders.get(source, {})
            file_stem = contract_info.get('file_stem', Path(source).stem) if contract_info else Path(source).stem
            contract_title = contract_info.get('contract_title', 'æœªå‘½ååˆåŒ') if contract_info else 'æœªå‘½ååˆåŒ'
            folder_path = contract_info.get('folder_path', '') if contract_info else ''
            avg_size = sum(len(c['text']) for c in contract_chunks) / len(contract_chunks) if contract_chunks else 0
            
            # ç»Ÿè®¡é‡è¦æ¡æ¬¾æ•°é‡
            important_clauses = [c for c in contract_chunks if c['metadata']['clause_priority'] <= 15]
            
            f.write(f"\n  ğŸ“„ æ–‡ä»¶: {source}\n")
            f.write(f"    æ–‡ä»¶å: {file_stem}\n")
            f.write(f"    åˆåŒæ ‡é¢˜: {contract_title}\n")
            f.write(f"    æ¡æ¬¾æ•°: {len(contract_chunks)}\n")
            f.write(f"    é‡è¦æ¡æ¬¾: {len(important_clauses)}\n")
            f.write(f"    å¹³å‡æ¡æ¬¾å¤§å°: {avg_size:.0f} å­—ç¬¦\n")
            f.write(f"    ä¿å­˜ä½ç½®: {folder_path}/\n")
        
        # æ¡æ¬¾ç±»å‹åˆ†å¸ƒ
        f.write(f"\nğŸ“‹ æ€»ä½“æ¡æ¬¾ç±»å‹åˆ†å¸ƒ\n")
        clause_types = {}
        for chunk in chunks:
            clause_type = chunk['metadata']['clause_type']
            clause_types[clause_type] = clause_types.get(clause_type, 0) + 1
        
        for clause_type, count in sorted(clause_types.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(chunks) * 100
            f.write(f"  {clause_type}: {count} æ¡ ({percentage:.1f}%)\n")
        
        # å½“äº‹äººåˆ†å¸ƒ
        f.write(f"\nğŸ‘¥ æ€»ä½“å½“äº‹äººåˆ†å¸ƒ\n")
        parties = {}
        for chunk in chunks:
            party = chunk['metadata']['contract_party']
            parties[party] = parties.get(party, 0) + 1
        
        for party, count in sorted(parties.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(chunks) * 100
            f.write(f"  {party}: {count} æ¡ ({percentage:.1f}%)\n")
        
        # ä¿å­˜ä½ç½®ä¿¡æ¯
        f.write(f"\nğŸ’¾ æ–‡ä»¶ä¿å­˜ä½ç½®\n")
        f.write(f"  æ€»ç»Ÿè®¡æ–‡ä»¶: {Path.cwd() / 'contract_chunks' / 'contracts_split_statistics.txt'}\n")
        f.write(f"  å„åˆåŒåˆ†å‰²ç»“æœ:\n")
        for source, info in contract_folders.items():
            file_stem = info.get('file_stem', Path(source).stem)
            folder_path = info.get('folder_path', '')
            f.write(f"    â€¢ {file_stem}: {folder_path}/\n")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("é€šç”¨åˆåŒæ–‡æ¡£åˆ†å‰²å™¨ - æŒ‰åˆåŒæ–‡ä»¶åå‘½åæ–‡ä»¶å¤¹")
    print("=" * 80)
    
    # é…ç½®å‚æ•°
    import argparse
    
    parser = argparse.ArgumentParser(description="é€šç”¨åˆåŒæ–‡æ¡£åˆ†å‰²å™¨")
    parser.add_argument("--input-dir", default="../docs/contracts_cleaned", help="è¾“å…¥åˆåŒç›®å½•")
    parser.add_argument("--output-dir", default="../docs/chunks/contract_chunks", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--chunk-size", type=int, default=1000, help="æ¡æ¬¾å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰")
    parser.add_argument("--min-length", type=int, default=30, help="æœ€å°æ¡æ¬¾é•¿åº¦")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = ContractDocumentProcessor(
        contracts_dir=args.input_dir,
        chunk_size=args.chunk_size,
        min_chunk_length=args.min_length
    )
    
    # 1. åŠ è½½åˆåŒ
    print(f"\n[æ­¥éª¤1] ä» '{args.input_dir}' åŠ è½½åˆåŒæ–‡æ¡£...")
    contracts = processor.load_all_documents()
    
    if not contracts:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯å¤„ç†çš„åˆåŒã€‚è¯·æ£€æŸ¥:")
        print(f"   1. ç›®å½•æ˜¯å¦å­˜åœ¨: {args.input_dir}")
        print(f"   2. ç›®å½•ä¸­æ˜¯å¦æœ‰.docxæˆ–.docæ–‡ä»¶")
        print(f"   3. ç¡®ä¿åˆåŒæ–‡æ¡£æ”¾åœ¨æ­£ç¡®ç›®å½•")
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½ {len(contracts)} ä¸ªåˆåŒ")
    
    # 2. åˆ†å‰²åˆåŒ
    print(f"\n[æ­¥éª¤2] æŒ‰æ¡æ¬¾åˆ†å‰²åˆåŒ...")
    chunks = processor.process_documents()
    print(f"âœ… æ€»åˆ†å‰²æ¡æ¬¾æ•°: {len(chunks)}")
    
    # 3. ä¿å­˜ç»“æœ
    print(f"\n[æ­¥éª¤3] ä¿å­˜åˆ†å‰²ç»“æœåˆ° '{args.output_dir}'...")
    print("  æŒ‰åˆåŒæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰åˆ›å»ºæ–‡ä»¶å¤¹ï¼Œä¿å­˜åˆ†å‰²ç»“æœ:")
    output_path = processor.save_results(chunks, args.output_dir)
    
    # 4. æ˜¾ç¤ºæ€»ç»“
    print(f"\n" + "=" * 80)
    print("å¤„ç†å®Œæˆ!")
    print("=" * 80)
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    if chunks:
        print(f"\nğŸ“‹ å¤„ç†æ‘˜è¦:")
        print(f"  â€¢ è¾“å…¥åˆåŒ: {len(contracts)} ä¸ª")
        print(f"  â€¢ è¾“å‡ºæ¡æ¬¾: {len(chunks)} æ¡")
        print(f"  â€¢ è¾“å‡ºç›®å½•: {output_path}")
        
        # æ˜¾ç¤ºå„åˆåŒçš„è¾“å‡ºä½ç½®
        print(f"\nğŸ“ å„åˆåŒè¾“å‡ºä½ç½®:")
        for contract in contracts:
            if contract['extraction_success']:
                file_stem = contract['file_stem']
                safe_name = processor._make_valid_folder_name(file_stem)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åŒåæ–‡ä»¶å¤¹ï¼Œå¦‚æœæœ‰åˆ™æ·»åŠ åºå·
                contract_folder = Path(output_path) / safe_name
                if not contract_folder.exists():
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå¯èƒ½æ˜¯å› ä¸ºæœ‰ç¼–å·åç¼€ï¼Œå°è¯•æŸ¥æ‰¾
                    matching_folders = list(Path(output_path).glob(f"{safe_name}*"))
                    if matching_folders:
                        contract_folder = matching_folders[0]
                
                if contract_folder.exists():
                    print(f"  â€¢ {file_stem}: {contract_folder.name}/")

if __name__ == "__main__":
    main()